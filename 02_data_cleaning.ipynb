{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad06734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import json\n",
    "\n",
    "os.chdir(\"../motum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6723c",
   "metadata": {},
   "source": [
    "## Motum dataset info\n",
    "- radiomics are stored in `motum/derivatives/*/*_radiomics.csv`\n",
    "    - there is one for each modality (t1,t1ce,t2,flair) for each patient (e.g. sub-0001)\n",
    "- corresponding json w scanner info in `motum/derivatives/*/*_params.json`\n",
    "    - similar to above there is one for each modality (t1,t1ce,t2,flair) for each patient \n",
    "- clinical metadata is stored in `motum/Participants.xlsx`\n",
    "\n",
    "GOAL:\n",
    "- can we distinguish between gliomas (cancers originating in the brain) and brain metastasis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e757c9",
   "metadata": {},
   "source": [
    "### Participant metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de0188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (67, 18)\n",
      "Shape: (67, 19)\n",
      "         ID   Sex  Age at MRI WHO CNS Grade Origin Pathology diagnosis  \\\n",
      "0  sub-0001  Male          79             3      /   Oligodendroglioma   \n",
      "1  sub-0002  Male          54             3      /   Oligodendroglioma   \n",
      "2  sub-0003  Male          78             3      /   Oligodendroglioma   \n",
      "3  sub-0004  Male          65             3      /         Astrocytoma   \n",
      "4  sub-0005  Male          48             3      /   Oligodendroglioma   \n",
      "\n",
      "        IDH GFAP         P53 Ki-67 Olig-2 Surgery or Biopsy  \\\n",
      "0  wildtype    +         +/-  35%+      +          Surgery    \n",
      "1  wildtype    +  partially+  30%+      +          Surgery    \n",
      "2    mutant    +           +  30%+      +          Surgery    \n",
      "3  wildtype    +           +  10%+      +          Surgery    \n",
      "4    mutant    +  partially+  40%+      +          Surgery    \n",
      "\n",
      "     Extent of Resection (EOR) Molecular Result  Image rating: FLAIR  \\\n",
      "0   Near total resection (NTR)                /                    2   \n",
      "1     Subtotal resection (STR)                /                    2   \n",
      "2  Gross total resection (GTR)                /                    2   \n",
      "3     Subtotal resection (STR)                /                    2   \n",
      "4  Gross total resection (GTR)                /                    2   \n",
      "\n",
      "   Image rating: T1  Image rating: T1-ce  Image rating: T2   label  \n",
      "0                 2                    1                 1  glioma  \n",
      "1                 2                    2                 2  glioma  \n",
      "2                 2                    2                 2  glioma  \n",
      "3                 1                    1                 1  glioma  \n",
      "4                 2                    2                 2  glioma  \n",
      "label\n",
      "metastasis    38\n",
      "glioma        29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "participants_file = \"Participants.xlsx\"\n",
    "md = pd.read_excel(participants_file)\n",
    "print(\"Shape:\", md.shape)\n",
    "\n",
    "# if not origin in the brain, glioma else metastasis\n",
    "# manually checked to confirm\n",
    "#  '/' for [Oligodendroglioma, Astrocytoma, Glioblastoma]\n",
    "md[\"label\"] = md[\"Origin\"].apply(lambda x: 'glioma' if x == '/' else 'metastasis')\n",
    "print(\"Shape:\", md.shape)\n",
    "print(md.head())\n",
    "\n",
    "md.to_csv(\"Participants_wlabels.csv\", index=False, na_rep=\"NA\")\n",
    "\n",
    "# checking counts for number of glioma and number of metastases\n",
    "# seeing if they match what is reported in the paper\n",
    "# 29 pts with high grade gliomas, 38 with brain metastases\n",
    "print(md[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07f790",
   "metadata": {},
   "source": [
    "## Compile Radiomics metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce5ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_header = [\n",
    "    \"Image\",\n",
    "    \"Mask\",\n",
    "    \"diagnostics_Versions_PyRadiomics\",\n",
    "    \"diagnostics_Versions_Numpy\",\n",
    "    \"diagnostics_Versions_SimpleITK\",\n",
    "    \"diagnostics_Versions_PyWavelet\",\n",
    "    \"diagnostics_Versions_Python\",\n",
    "    \"diagnostics_Configuration_Settings\",\n",
    "    \"diagnostics_Configuration_EnabledImageTypes\",\n",
    "    \"diagnostics_Image-original_Hash\",\n",
    "    \"diagnostics_Image-original_Dimensionality\",\n",
    "    \"diagnostics_Image-original_Spacing\",\n",
    "    \"diagnostics_Image-original_Size\",\n",
    "    \"diagnostics_Image-original_Mean\",\n",
    "    \"diagnostics_Image-original_Minimum\",\n",
    "    \"diagnostics_Image-original_Maximum\",\n",
    "    \"diagnostics_Mask-original_Hash\",\n",
    "    \"diagnostics_Mask-original_Spacing\",\n",
    "    \"diagnostics_Mask-original_Size\",\n",
    "    \"diagnostics_Mask-original_BoundingBox\",\n",
    "    \"diagnostics_Mask-original_VoxelNum\",\n",
    "    \"diagnostics_Mask-original_VolumeNum\",\n",
    "    \"diagnostics_Mask-original_CenterOfMassIndex\",\n",
    "    \"diagnostics_Mask-original_CenterOfMass\",\n",
    "    \"original_shape_Elongation\",\n",
    "    \"original_shape_Flatness\",\n",
    "    \"original_shape_LeastAxisLength\",\n",
    "    \"original_shape_MajorAxisLength\",\n",
    "    \"original_shape_Maximum2DDiameterColumn\",\n",
    "    \"original_shape_Maximum2DDiameterRow\",\n",
    "    \"original_shape_Maximum2DDiameterSlice\",\n",
    "    \"original_shape_Maximum3DDiameter\",\n",
    "    \"original_shape_MeshVolume\",\n",
    "    \"original_shape_MinorAxisLength\",\n",
    "    \"original_shape_Sphericity\",\n",
    "    \"original_shape_SurfaceArea\",\n",
    "    \"original_shape_SurfaceVolumeRatio\",\n",
    "    \"original_shape_VoxelVolume\",\n",
    "    \"original_firstorder_10Percentile\",\n",
    "    \"original_firstorder_90Percentile\",\n",
    "    \"original_firstorder_Energy\",\n",
    "    \"original_firstorder_Entropy\",\n",
    "    \"original_firstorder_InterquartileRange\",\n",
    "    \"original_firstorder_Kurtosis\",\n",
    "    \"original_firstorder_Maximum\",\n",
    "    \"original_firstorder_MeanAbsoluteDeviation\",\n",
    "    \"original_firstorder_Mean\",\n",
    "    \"original_firstorder_Median\",\n",
    "    \"original_firstorder_Minimum\",\n",
    "    \"original_firstorder_Range\",\n",
    "    \"original_firstorder_RobustMeanAbsoluteDeviation\",\n",
    "    \"original_firstorder_RootMeanSquared\",\n",
    "    \"original_firstorder_Skewness\",\n",
    "    \"original_firstorder_TotalEnergy\",\n",
    "    \"original_firstorder_Uniformity\",\n",
    "    \"original_firstorder_Variance\",\n",
    "    \"original_glcm_Autocorrelation\",\n",
    "    \"original_glcm_ClusterProminence\",\n",
    "    \"original_glcm_ClusterShade\",\n",
    "    \"original_glcm_ClusterTendency\",\n",
    "    \"original_glcm_Contrast\",\n",
    "    \"original_glcm_Correlation\",\n",
    "    \"original_glcm_DifferenceAverage\",\n",
    "    \"original_glcm_DifferenceEntropy\",\n",
    "    \"original_glcm_DifferenceVariance\",\n",
    "    \"original_glcm_Id\",\n",
    "    \"original_glcm_Idm\",\n",
    "    \"original_glcm_Idmn\",\n",
    "    \"original_glcm_Idn\",\n",
    "    \"original_glcm_Imc1\",\n",
    "    \"original_glcm_Imc2\",\n",
    "    \"original_glcm_InverseVariance\",\n",
    "    \"original_glcm_JointAverage\",\n",
    "    \"original_glcm_JointEnergy\",\n",
    "    \"original_glcm_JointEntropy\",\n",
    "    \"original_glcm_MCC\",\n",
    "    \"original_glcm_MaximumProbability\",\n",
    "    \"original_glcm_SumAverage\",\n",
    "    \"original_glcm_SumEntropy\",\n",
    "    \"original_glcm_SumSquares\",\n",
    "    \"original_gldm_DependenceEntropy\",\n",
    "    \"original_gldm_DependenceNonUniformity\",\n",
    "    \"original_gldm_DependenceNonUniformityNormalized\",\n",
    "    \"original_gldm_DependenceVariance\",\n",
    "    \"original_gldm_GrayLevelNonUniformity\",\n",
    "    \"original_gldm_GrayLevelVariance\",\n",
    "    \"original_gldm_HighGrayLevelEmphasis\",\n",
    "    \"original_gldm_LargeDependenceEmphasis\",\n",
    "    \"original_gldm_LargeDependenceHighGrayLevelEmphasis\",\n",
    "    \"original_gldm_LargeDependenceLowGrayLevelEmphasis\",\n",
    "    \"original_gldm_LowGrayLevelEmphasis\",\n",
    "    \"original_gldm_SmallDependenceEmphasis\",\n",
    "    \"original_gldm_SmallDependenceHighGrayLevelEmphasis\",\n",
    "    \"original_gldm_SmallDependenceLowGrayLevelEmphasis\",\n",
    "    \"original_glrlm_GrayLevelNonUniformity\",\n",
    "    \"original_glrlm_GrayLevelNonUniformityNormalized\",\n",
    "    \"original_glrlm_GrayLevelVariance\",\n",
    "    \"original_glrlm_HighGrayLevelRunEmphasis\",\n",
    "    \"original_glrlm_LongRunEmphasis\",\n",
    "    \"original_glrlm_LongRunHighGrayLevelEmphasis\",\n",
    "    \"original_glrlm_LongRunLowGrayLevelEmphasis\",\n",
    "    \"original_glrlm_LowGrayLevelRunEmphasis\",\n",
    "    \"original_glrlm_RunEntropy\",\n",
    "    \"original_glrlm_RunLengthNonUniformity\",\n",
    "    \"original_glrlm_RunLengthNonUniformityNormalized\",\n",
    "    \"original_glrlm_RunPercentage\",\n",
    "    \"original_glrlm_RunVariance\",\n",
    "    \"original_glrlm_ShortRunEmphasis\",\n",
    "    \"original_glrlm_ShortRunHighGrayLevelEmphasis\",\n",
    "    \"original_glrlm_ShortRunLowGrayLevelEmphasis\",\n",
    "    \"original_glszm_GrayLevelNonUniformity\",\n",
    "    \"original_glszm_GrayLevelNonUniformityNormalized\",\n",
    "    \"original_glszm_GrayLevelVariance\",\n",
    "    \"original_glszm_HighGrayLevelZoneEmphasis\",\n",
    "    \"original_glszm_LargeAreaEmphasis\",\n",
    "    \"original_glszm_LargeAreaHighGrayLevelEmphasis\",\n",
    "    \"original_glszm_LargeAreaLowGrayLevelEmphasis\",\n",
    "    \"original_glszm_LowGrayLevelZoneEmphasis\",\n",
    "    \"original_glszm_SizeZoneNonUniformity\",\n",
    "    \"original_glszm_SizeZoneNonUniformityNormalized\",\n",
    "    \"original_glszm_SmallAreaEmphasis\",\n",
    "    \"original_glszm_SmallAreaHighGrayLevelEmphasis\",\n",
    "    \"original_glszm_SmallAreaLowGrayLevelEmphasis\",\n",
    "    \"original_glszm_ZoneEntropy\",\n",
    "    \"original_glszm_ZonePercentage\",\n",
    "    \"original_glszm_ZoneVariance\",\n",
    "    \"original_ngtdm_Busyness\",\n",
    "    \"original_ngtdm_Coarseness\",\n",
    "    \"original_ngtdm_Complexity\",\n",
    "    \"original_ngtdm_Contrast\",\n",
    "    \"original_ngtdm_Strength\",\n",
    "    \"ManufacturerModelName\", # added from *param.json\n",
    "    \"RepetitionTime\", # added from *param.json\n",
    "    \"EchoTime\", # added from *param.json\n",
    "    \"InversionTime\", # added from *param.json\n",
    "    \"FlipAngle\", # added from *param.json\n",
    "    \"SliceThickness\", # added from *param.json\n",
    "    \"PixelSpacing\", # added from *param.json\n",
    "    \"subject_id\" # based on dir\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fe668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7}\n"
     ]
    }
   ],
   "source": [
    "# check for consistency across all jsons - YES all 7\n",
    "param_files = glob.glob(\"**/*_param.json\", recursive=True)\n",
    "# print(param_files)\n",
    "lens = []\n",
    "for f in param_files:\n",
    "    with open(f, 'r') as json_file:\n",
    "        jfile = json.load(json_file)\n",
    "        lens.append(len(jfile.keys()))\n",
    "\n",
    "print(set(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564c4e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 73 files are missing corresponding radiomics data\n",
      "{'t1': ['sub-0024', 'sub-0048', 'sub-0057'], 't1ce': ['sub-0015', 'sub-0012', 'sub-0024', 'sub-0023', 'sub-0048', 'sub-0046', 'sub-0041', 'sub-0022', 'sub-0013', 'sub-0014', 'sub-0040', 'sub-0047', 'sub-0049', 'sub-0054', 'sub-0053', 'sub-0065', 'sub-0062', 'sub-0009', 'sub-0036', 'sub-0031', 'sub-0038', 'sub-0007', 'sub-0063', 'sub-0064', 'sub-0052', 'sub-0055', 'sub-0001', 'sub-0006', 'sub-0030', 'sub-0008', 'sub-0042', 'sub-0045', 'sub-0011', 'sub-0016', 'sub-0029', 'sub-0020', 'sub-0027', 'sub-0018', 'sub-0044', 'sub-0043', 'sub-0026', 'sub-0019', 'sub-0021', 'sub-0017', 'sub-0028', 'sub-0010', 'sub-0032', 'sub-0035', 'sub-0003', 'sub-0004', 'sub-0050', 'sub-0057', 'sub-0061', 'sub-0066', 'sub-0059', 'sub-0005', 'sub-0002', 'sub-0034', 'sub-0033', 'sub-0067', 'sub-0058', 'sub-0060', 'sub-0056', 'sub-0051'], 't2': ['sub-0024', 'sub-0048', 'sub-0057'], 'flair': ['sub-0024', 'sub-0048', 'sub-0057']}\n",
      "{'t1': 3, 't1ce': 64, 't2': 3, 'flair': 3}\n"
     ]
    }
   ],
   "source": [
    "## ----- parse each radiomics.csv and param.json -----\n",
    "os.chdir(\"derivatives\")\n",
    "clean_dir = \"../clean_radiomics_data\"\n",
    "os.makedirs(clean_dir, exist_ok=True)\n",
    "radiomics_files = glob.glob(f\"**/*_radiomics.csv\", recursive=True)\n",
    "# print(radiomics_files)\n",
    "\n",
    "missing_file_count = 0\n",
    "missing_type = {\n",
    "    \"t1\":[],\n",
    "    \"t1ce\":[],\n",
    "    \"t2\":[],\n",
    "    \"flair\":[]\n",
    "}\n",
    "# drop duplicate headers and make clean files for each - pd struggles w this\n",
    "for f in radiomics_files:\n",
    "    clean_rows = []\n",
    "    subject_id = f.split('/')[-2]\n",
    "    filename = os.path.basename(f)\n",
    "    modality = filename.split('_')[0]\n",
    "\n",
    "    # from manual inspec, some files don't have any radiomics data\n",
    "    # ex: sub-0024/t1ce_radiomics.csv only has image and mask\n",
    "    missing_fields = set()\n",
    "    with open(f, 'r') as input_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        header = next(reader) # treat first row as header to begin with\n",
    "        for line in reader:\n",
    "            image_file = line[0].split('/')[-1]\n",
    "            # if modality not in image_file: # single out problematic files (i.e. mismatch modality)\n",
    "            #     continue\n",
    "            if (\n",
    "                line[0] == 'Image'\n",
    "                and len(line) > len(header)\n",
    "                and modality in line[0]\n",
    "            ):\n",
    "                # somehow need to skip if it precedes wrong modality\n",
    "                header = line\n",
    "\n",
    "        with open(f\"{subject_id}/{modality}_param.json\", 'r') as json_file:\n",
    "            jfile = json.load(json_file)\n",
    "\n",
    "        new_header = header + list(jfile.keys()) + ['subject_id']\n",
    "\n",
    "\n",
    "        # if len(full_header) != len(new_header) and len(new_header) == 2:\n",
    "        assert not (set(new_header) - set(full_header)), f\"{f} has headers not in the general list\"\n",
    "\n",
    "        if len(full_header) != len(new_header):\n",
    "            missing_fields = set(full_header) - set(new_header)\n",
    "            missing_file_count += 1\n",
    "            missing_type[modality].append(subject_id)\n",
    "\n",
    "    with open(f, 'r') as input_file:\n",
    "        reader = csv.reader(input_file)\n",
    "        # header = next(reader) # handle earlier\n",
    "\n",
    "        seen = set()\n",
    "        for row in reader:\n",
    "            # different types of rows to skip\n",
    "            if row[0] == 'Image': # header row or duplicate\n",
    "                continue\n",
    "\n",
    "            # if len(row) == 2: # just image and masks\n",
    "            if len(row) != len(header): # skip incomplete entries if there are others \n",
    "                continue\n",
    "            \n",
    "            # handle files like 'sub-0015/t1ce_radiomics.csv' which have some mismatched radiomics\n",
    "            image_file = row[0].split('/')[-1]\n",
    "            if modality not in image_file:\n",
    "                continue\n",
    "\n",
    "            if missing_fields:\n",
    "                assert len(row) == 2, (\n",
    "                    f\"file:{f} has fields beside image and mask:\\n{row}\"\n",
    "                )\n",
    "                header_len = len(header)\n",
    "                param_len = len(list(jfile.keys()))\n",
    "                row.extend([\"NA\"] * (len(missing_fields)))\n",
    "\n",
    "          \n",
    "            row_tuple = tuple(row)\n",
    "            if row_tuple in seen: # skip duplicate rows\n",
    "                continue\n",
    "            # need to somehow handle cases where they're ALMOST identical (e.g. radiomics rounding error)\n",
    "            seen.add(row_tuple)\n",
    "\n",
    "            # print(len(row))\n",
    "            # print(len(header))\n",
    "            # assert len(full_header) == len(row), ( # make sure equivalent no of entries\n",
    "            #     f\"file:{f}\\nheader={len(full_header)}, row={len(row)}\\n{row}\"\n",
    "            # )\n",
    "            # assert len(new_header) == len(row), f\"{set(map(str, new_header)) ^ set(map(str, row))}\"\n",
    "            clean_rows.append(row)\n",
    "\n",
    "    if not clean_rows: # in cases where no correct modality radiomics data was found\n",
    "        clean_rows.extend([\"NA\"] * len(header))\n",
    "\n",
    "    elif len(clean_rows) > 1:\n",
    "        # multiple rows are identical w rounding diff select subsequent ones\n",
    "        first_entry = len(clean_rows[0])\n",
    "        if not all(len(r) == first_entry for r in clean_rows):\n",
    "            print(f\"duplicate entries differ in length:{clean_rows}\")\n",
    "            max_ind = clean_rows.index(max(clean_rows, key=len))\n",
    "            clean_row = clean_rows[max_ind]\n",
    "\n",
    "        else: # stick with last entry\n",
    "            clean_row = clean_rows[-1]\n",
    "    else:\n",
    "        clean_row = clean_rows[0]\n",
    "\n",
    "\n",
    "    # fix to handle mising values better\n",
    "    new_vals = [jfile.get(k, '') for k in jfile.keys()] + [subject_id]\n",
    "    clean_row.extend(new_vals)\n",
    "\n",
    "    assert len(full_header) == len(clean_row), (\n",
    "        f\"file:{f}\\nheader={len(full_header)}, row={len(clean_row)}\\n{clean_row}\"\n",
    "            )\n",
    "\n",
    "    # write out clean_csv\n",
    "    with open(f\"{clean_dir}/{subject_id}_{filename}\", \"w\", newline=\"\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(full_header)\n",
    "        writer.writerow(clean_row)\n",
    "\n",
    "print(f\"In total {missing_file_count} files are missing corresponding radiomics data\")\n",
    "print(missing_type)\n",
    "counts_dict = {key: len(value) for key, value in missing_type.items()}\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67343476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 entries\n"
     ]
    }
   ],
   "source": [
    "## ----- agg all correpsonding metadata -----\n",
    "## now referencing clean files, agg diff data\n",
    "clean_rad_files = glob.glob(f\"{clean_dir}/*radiomics.csv\") # can FINALLY parse :')\n",
    "\n",
    "# read and concat csv\n",
    "df_list = [pd.read_csv(f) for f in clean_rad_files]\n",
    "print(f\"{len(df_list)} entries\")\n",
    "\n",
    "## SANITY CHECKS\n",
    "FIRST = \"Image\"\n",
    "for df in df_list:\n",
    "    if len(df) != 1:\n",
    "        print(f\"More than one entry\")\n",
    "    assert FIRST in df.columns, \"Missing expected first column\"\n",
    "    # assert not (df.iloc[:, 0] == \"NA\").any(), \"Found 'NA' in first column\"\n",
    "    first_col = df.columns[0]\n",
    "    assert not (df[first_col].isna() | (df[first_col] == \"NA\")).any(), \\\n",
    "        f\"Found missing in first column for {df}\"\n",
    "\n",
    "merged_df = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "# fill missing values with \"NA\" and drop duplicates if any missed\n",
    "merged_df = merged_df.fillna(\"NA\").drop_duplicates()\n",
    "\n",
    "# save merged output\n",
    "merged_df.to_csv(\"../merged_radiomics_data.csv\", index=False, na_rep=\"NA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS3000env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
